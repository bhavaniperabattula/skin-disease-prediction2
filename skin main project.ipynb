#IMPORTING LIBRARIES
import os
import time
import shutil
import itertools
import random

# import data handling tools 
import cv2
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# import Deep learning Libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization
from tensorflow.keras.models import Model, load_model, Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras import regularizers
from tensorflow.keras.metrics import categorical_crossentropy
import warnings
warnings.filterwarnings('ignore')

#READ DATA
data_dir = "hmnist_28_28_RGB.csv"
data = pd.read_csv(data_dir)
data.head()
data.tail()
data.shape
data.describe()
#DATA PREPROCESSING

#SPLIT DATA AND LABELS
Label = data["label"]
Data = data.drop(columns=["label"])
data["label"].value_counts()

#HANDLING IMBALANCED DATASETS

from imblearn.over_sampling import RandomOverSampler   #augmentation

oversample = RandomOverSampler()
Data, Label  = oversample.fit_resample(Data, Label)
Data = np.array(Data).reshape(-1, 28, 28, 3)
print('Shape of Data :', Data.shape)
Label = np.array(Label)
Label
data.isnull().sum()

#CONVERTING ABBREVIATIONS TO ITS WORDS

classes = {
    4: ('nv', 'Melanocytic nevi', ['Sensitivity to touch around the mole', 'Redness or inflammation around the mole'],['Avoid tight Clothing','Limit exposure to direct sunlight']),
    6: ('mel', 'Melanoma', ['Multiple colors within a mole', 'Bleeding or oozing from a mole'],['Eat a balanced diet rich in antioxidants and vitamins','Avoid smoking and limit alcohol consumption']),
    2: ('bkl', 'Benign keratosis-like lesions',  ['Itching or irritation in affected areas, Round or oval shaped growths', 'Very small growths clustered around the eyes or elsewhere on the face'],['Moisturize Regularly','Manage Stress by meditation or yoga']),
    1: ('bcc', 'Basal cell carcinoma', ['Surrounding skin becoming sunken or depressed','Formation of a flesh-coloured, pearl like bump'],['Avoid harmful chemicals','Wear Protective Clothing']),
    5: ('vasc', 'Pyogenic granulomas and hemorrhage', ['Prone to Ulceration', 'Moist or friable surface structure'],['Use sunscreen with a high SPF','Keep the affected arear covered with a sterile dressing']),
    0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae', ['Swelling and burning in affected region', 'Thickening of the skin'],['Avoid tanning beds and sunlamps','Avoid hot shower and opt for lukewarm water']),
    3: ('df', 'Dermatofibroma', ['Dimpled appearance when pressed', 'Growing in size over time'],['Avoid using harsh chemicals or irritants','Drink plenty of water and maintain proper hydration']) 
    
}

#SPLITING TRAIN AND TEST

from sklearn.model_selection import train_test_split

# Assuming you have 'Data' and 'Label' from your previous code
# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(Data, Label, test_size=0.2, random_state=42)

# Now you can use X_test in the provided code block
plt.figure(figsize=(10, 10))
for i in range(16): 
    plt.subplot(4, 4, i + 1)  # Create a subplot
    plt.imshow(X_test[i])    # Display the image
    plt.axis('off')           # Turn off axis labels
plt.show()

from sklearn.model_selection import train_test_split
X_train , X_test , y_train , y_test = train_test_split(Data , Label , test_size = 0.25 , random_state = 49)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

import matplotlib.pyplot as plt
import seaborn as sns

# Example: Histogram of label counts
sns.countplot(data=data, x='label')
plt.xlabel('Skin Cancer Class')
plt.ylabel('Count')
plt.title('Distribution of Skin Cancer Classes')
plt.show()

#Convert labels to categorical types

from tensorflow.keras.utils import to_categorical

# Your other code...

# Convert labels to categorical
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

y_train.shape

print(y_train[0])

ind= random.randint(1,10000)
plt.imshow(X_train[ind], cmap='gray')
# plt.axis('off')
plt.title("Random image from training data")
plt.show()

#Model Structure

model = keras.models.Sequential()

# Create Model Structure
model.add(keras.layers.Input(shape=[28, 28, 3]))
model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
model.add(keras.layers.MaxPooling2D())
model.add(keras.layers.BatchNormalization())

model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
model.add(keras.layers.MaxPooling2D())
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
model.add(keras.layers.MaxPooling2D())
model.add(keras.layers.BatchNormalization())

# model.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
# model.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'))
# model.add(keras.layers.MaxPooling2D())

model.add(keras.layers.Flatten())
model.add(keras.layers.Dropout(rate=0.2))
# model.add(keras.layers.Dense(units=256, activation='relu', kernel_initializer='he_normal'))
# model.add(keras.layers.BatchNormalization())

model.add(keras.layers.Dense(units=128, activation='relu', kernel_initializer='he_normal'))
model.add(keras.layers.BatchNormalization())

model.add(keras.layers.Dense(units=64, activation='relu', kernel_initializer='he_normal'))
model.add(keras.layers.BatchNormalization())

model.add(keras.layers.Dense(units=32, activation='relu', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.L1L2()))
model.add(keras.layers.BatchNormalization())

model.add(keras.layers.Dense(units=7, activation='softmax'))
model.compile(Adam(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])

model.summary()

#Training model

from tensorflow.keras.callbacks import ReduceLROnPlateau

# Define the learning rate reduction callback
learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', 
                                            patience=2, 
                                            verbose=1, 
                                            factor=0.5, 
                                            min_lr=0.00001)

# Use the callback in model.fit()
history = model.fit(X_train ,
                    y_train ,
                    epochs=25,
                    batch_size=128,
                    validation_data=(X_test , y_test) ,
                    callbacks=[learning_rate_reduction])

from keras.utils import to_categorical

# Assuming y_train is your categorical labels
y_train_encoded = to_categorical(y_train, num_classes=7)

y_test_encoded = to_categorical(y_test, num_classes=7)

#Show training history

def plot_training(hist):
    tr_acc = hist.history['accuracy']
    tr_loss = hist.history['loss']
    val_acc = hist.history['val_accuracy']
    val_loss = hist.history['val_loss']
    index_loss = np.argmin(val_loss)
    val_lowest = val_loss[index_loss]
    index_acc = np.argmax(val_acc)
    acc_highest = val_acc[index_acc]

    plt.figure(figsize= (20, 8))
    plt.style.use('fivethirtyeight')
    Epochs = [i+1 for i in range(len(tr_acc))]
    loss_label = f'best epoch= {str(index_loss + 1)}'
    acc_label = f'best epoch= {str(index_acc + 1)}'
    
    plt.subplot(1, 2, 1)
    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')
    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')
    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')
    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')
    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    
    plt.tight_layout
    plt.show()

plot_training(history)

#Model Evaluation

train_score = model.evaluate(X_train, y_train, verbose= 1)
test_score = model.evaluate(X_test, y_test, verbose= 1)

print("Train Loss: ", train_score[0])
print("Train Accuracy: ", train_score[1])
print('-' * 20)
print("Test Loss: ", test_score[0])
print("Test Accuracy: ", test_score[1])

y_true = np.array(y_test)
y_pred = model.predict(X_test)

y_pred = np.argmax(y_pred , axis=1)
y_true = np.argmax(y_true , axis=1)

#CREATE CLASSES LABELS

classes_labels = []
for key in classes.keys():
    classes_labels.append(key)

print(classes_labels)

#SAVE THE MODEL

model.save("skin_cancer.h5")

import cv2
import os
from PIL import Image
import numpy as np

directory = "C:\\Users\\srika\\skin\\disease"
for subdir, dirs, files in os.walk(directory):
    for file in files:
        file_path = os.path.join(subdir, file)
        if file_path.endswith(".jpg") or file_path.endswith('.jpeg') or file_path.endswith(".png"):
            # Load and preprocess the image
            image = Image.open(file_path)
            image = image.resize((28, 28))
            img = np.array(image).reshape(-1, 28, 28, 3)
            
            # Predict the disease
            result = model.predict(img)
            max_prob = max(result[0])
            class_ind = result[0].tolist().index(max_prob)
            
            # Get disease information from the classes dictionary
            disease_code, disease_name, symptoms, precautions = classes[class_ind]
            
            # Calculate confidence as a percentage
            confidence_percentage = max_prob * 100
            
            # Extract filename without extension and folder name from file_path
            folder_name = os.path.basename(os.path.dirname(file_path))
            file_name = os.path.splitext(os.path.basename(file_path))[0]
            
            print("Predicted:", disease_name)
            print("Confidence:", f"{confidence_percentage:.2f}%")  # Print confidence as a percentage with 2 decimal places
            print("Symptoms:")
            for symptom in symptoms:
                print("- " + symptom)
            print("Precautions:")
            for precaution in precautions:
                print("- " + precaution)
            
            # Display the image
            test_img = cv2.imread(file_path)
            plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))
            plt.axis('off')
            plt.show()

print(classification_report(y_true,y_pred,labels=classes_labels))

cm = cm = confusion_matrix(y_true, y_pred, labels=classes_labels)
plt.figure(figsize= (10, 10))
plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation= 45)
plt.yticks(tick_marks, classes)
thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')
plt.tight_layout()
plt.ylabel('True Label')
plt.xlabel('Predicted label')
plt.show()
